{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# df = pd.read_csv(\"../../datasets/情感分析/train.txt\",delimiter=\";\",names=['sentence','label'])\n",
    "# df.to_csv(\"train.csv\", encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "                                            sentence     label\n0                            i didnt feel humiliated   sadness\n1  i can go from feeling so hopeless to so damned...   sadness\n2   im grabbing a minute to post i feel greedy wrong     anger\n3  i am ever feeling nostalgic about the fireplac...      love\n4                               i am feeling grouchy     anger\n5  ive been feeling a little burdened lately wasn...   sadness\n6  ive been taking or milligrams or times recomme...  surprise\n7  i feel as confused about life as a teenager or...      fear\n8  i have been with petronas for years i feel tha...       joy\n9                                i feel romantic too      love",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>i didnt feel humiliated</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i can go from feeling so hopeless to so damned...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>im grabbing a minute to post i feel greedy wrong</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i am ever feeling nostalgic about the fireplac...</td>\n      <td>love</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i am feeling grouchy</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ive been feeling a little burdened lately wasn...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>ive been taking or milligrams or times recomme...</td>\n      <td>surprise</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>i feel as confused about life as a teenager or...</td>\n      <td>fear</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>i have been with petronas for years i feel tha...</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>i feel romantic too</td>\n      <td>love</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('train.csv')\n",
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 2)\n",
      "sentence    0\n",
      "label       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.isnull().sum())   # 检查空值"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "# 需要映入的库\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "def review_to_words(raw_review):\n",
    "    # 通过BeautifulSoup抽取纯文本\n",
    "    review_text = BeautifulSoup(raw_review).get_text()\n",
    "    # 通过正则表达式去掉标点符号\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n",
    "    # 转化为小写，并进行分词\n",
    "    words = letters_only.lower().split()\n",
    "    # 去停用词\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    meaningful_words = [w for w in words if w not in stops]\n",
    "\n",
    "    # print(meaningful_words)\n",
    "    # 还原词性\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    r_words = [lemmatizer.lemmatize(w) for w in  meaningful_words]\n",
    "\n",
    "    # 将处理后的数据返回\n",
    "    cleaned_review = \" \".join(r_words)\n",
    "    return cleaned_review\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "didnt feel humiliated\n"
     ]
    }
   ],
   "source": [
    "clean_review = review_to_words(df[\"sentence\"][0])\n",
    "print(clean_review)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "# import re\n",
    "# import string\n",
    "# \"\"\"\n",
    "# 移除网址，$数字$, 数字， 标点符号\n",
    "# \"\"\"\n",
    "# def remove_hyperlinks(text):\n",
    "#     sentence = re.sub(r'www?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "#     sentence = re.sub(r'http?:\\/\\/.*[\\r\\n]*', '', sentence)\n",
    "#     return re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', sentence)\n",
    "#\n",
    "# def remove_currencies(text):\n",
    "#     return re.sub(r'[\\$\\d+\\d+\\$]', '', text)\n",
    "#\n",
    "# def remove_number(text):\n",
    "#     return re.sub(r'\\d+', '', text)\n",
    "#\n",
    "# def remove_punctuation(text):\n",
    "#     return ''.join([word for word in text if word not in string.punctuation])\n",
    "#\n",
    "# df['sentence'] = df['sentence'].apply(lambda x: remove_hyperlinks(x.lower()))\n",
    "# df['sentence'] = df['sentence'].apply(lambda x: remove_currencies(x))\n",
    "# df['sentence'] = df['sentence'].apply(lambda x: remove_number(x))\n",
    "# df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# stopword = stopwords.words('english')\n",
    "# print(stopword)\n",
    "# def remove_stopword(text):\n",
    "#     return [word for word in text if word not in stopword]\n",
    "#\n",
    "# df['sentence'] = df['sentence'].apply(lambda x: remove_stopword(x))\n",
    "# df.head(10)\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "# # 把一些名词的词性还原 如 cars-->car\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "# def lemmatize(text):\n",
    "#     return ' '.join([lemmatizer.lemmatize(word) for word in text])\n",
    "#\n",
    "# df['sentence'] = df['sentence'].apply(lambda x: lemmatize(x))\n",
    "# df.head(10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "出现报错 partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)\n",
    "解决方案 https://www.cnblogs.com/LHWorldBlog/p/9641374.html"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the training set movie reviews...\n",
      "\n",
      "Review 1000 of 16000 \n",
      "\n",
      "Review 2000 of 16000 \n",
      "\n",
      "Review 3000 of 16000 \n",
      "\n",
      "Review 4000 of 16000 \n",
      "\n",
      "Review 5000 of 16000 \n",
      "\n",
      "Review 6000 of 16000 \n",
      "\n",
      "Review 7000 of 16000 \n",
      "\n",
      "Review 8000 of 16000 \n",
      "\n",
      "Review 9000 of 16000 \n",
      "\n",
      "Review 10000 of 16000 \n",
      "\n",
      "Review 11000 of 16000 \n",
      "\n",
      "Review 12000 of 16000 \n",
      "\n",
      "Review 13000 of 16000 \n",
      "\n",
      "Review 14000 of 16000 \n",
      "\n",
      "Review 15000 of 16000 \n",
      "\n",
      "Review 16000 of 16000 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "['didnt feel humiliated',\n 'go feeling hopeless damned hopeful around someone care awake',\n 'im grabbing minute post feel greedy wrong',\n 'ever feeling nostalgic fireplace know still property',\n 'feeling grouchy']"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_reviews=len(df)\n",
    "# 对数据进行清洗\n",
    "clean_train_reviews=[]\n",
    "print(\"Cleaning and parsing the training set movie reviews...\\n\")\n",
    "for i in range(0,num_reviews):\n",
    "    if((i+1)%1000 == 0):\n",
    "        print(\"Review %d of %d \\n\" % (i+1, num_reviews))\n",
    "    temp_review=review_to_words(df[\"sentence\"][i])\n",
    "    clean_train_reviews.append(temp_review)\n",
    "clean_train_reviews[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "df['sentence'] = clean_train_reviews"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "                                            sentence     label\n0                              didnt feel humiliated   sadness\n1  go feeling hopeless damned hopeful around some...   sadness\n2          im grabbing minute post feel greedy wrong     anger\n3  ever feeling nostalgic fireplace know still pr...      love\n4                                    feeling grouchy     anger\n5      ive feeling little burdened lately wasnt sure   sadness\n6  ive taking milligram time recommended amount i...  surprise\n7     feel confused life teenager jaded year old man      fear\n8  petronas year feel petronas performed well mad...       joy\n9                                      feel romantic      love",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>didnt feel humiliated</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>go feeling hopeless damned hopeful around some...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>im grabbing minute post feel greedy wrong</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ever feeling nostalgic fireplace know still pr...</td>\n      <td>love</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>feeling grouchy</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ive feeling little burdened lately wasnt sure</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>ive taking milligram time recommended amount i...</td>\n      <td>surprise</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>feel confused life teenager jaded year old man</td>\n      <td>fear</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>petronas year feel petronas performed well mad...</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>feel romantic</td>\n      <td>love</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# 获取类别\n",
    "category = df[\"label\"].unique().tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "sentence = df['sentence'].values\n",
    "label = df[\"label\"].apply(lambda x: category.index(x)).values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "# 获取所有不重复的单词\n",
    "words = [word.lower() for s in sentence for word in s.split(\" \")]\n",
    "various_words = list(set(words))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "int2word = dict(enumerate(various_words))  # 索引到单词\n",
    "word2int = {w:int(i) for i,w in int2word.items()} # 单词到索引"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "Counter({0: 4666, 1: 2159, 2: 1304, 3: 572, 4: 1937, 5: 5362})"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "sentence_length = [len(s.split()) for s in sentence]   # 每个句子单词的个数\n",
    "counts = dict(Counter(sentence_length))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1152x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.bar(counts.keys(),counts.values())\n",
    "plt.xlabel(\"sentence_length\")\n",
    "plt.ylabel(\"num\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min:(1, 8), max:(35, 2)\n"
     ]
    }
   ],
   "source": [
    "min_sen = min(counts.items())\n",
    "max_sen = max(counts.items())\n",
    "print(\"min:{}, max:{}\".format(min_sen,max_sen))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    获取最小和最大长度的句子的索引\n",
    "\"\"\"\n",
    "min_index = [i for i,length in enumerate(sentence_length) if length==min_sen[0]]\n",
    "max_index = [i for i,length in enumerate(sentence_length) if length==max_sen[0]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始文本数量： 15992\n",
      "新文本数量:  15990\n"
     ]
    }
   ],
   "source": [
    "new_text = np.delete(sentence, min_index)\n",
    "new_text2 = np.delete(new_text, max_index)\n",
    "print(\"原始文本数量：\",len(new_text))\n",
    "print(\"新文本数量: \", len(new_text2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始标签数量： 15992\n",
      "新标签数量:  15990\n"
     ]
    }
   ],
   "source": [
    "new_labels = np.delete(label, min_index)\n",
    "new_labels = np.delete(new_labels, max_index)\n",
    "print(\"原始标签数量：\",len(new_text))\n",
    "print(\"新标签数量: \", len(new_text2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "text2ints = []\n",
    "for sentence in new_text2:\n",
    "    sample = list()\n",
    "    for word in sentence.split():\n",
    "        int_value = word2int[word]\n",
    "        sample.append(int_value)\n",
    "    text2ints.append(sample)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "[[4462, 12249, 3478],\n [12895, 8576, 10651, 12549, 9685, 6183, 6867, 11221, 507],\n [8103, 8820, 5447, 711, 12249, 2056, 1117],\n [10354, 8576, 13471, 9298, 841, 4074, 10742],\n [8576, 2381]]"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2ints[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 4462., 12249.,  3478., ...,     0.,     0.,     0.],\n       [12895.,  8576., 10651., ...,     0.,     0.,     0.],\n       [ 8103.,  8820.,  5447., ...,     0.,     0.,     0.],\n       ...,\n       [12249.,  9863.,  6274., ...,     0.,     0.,     0.],\n       [12249.,  1214.,  4355., ...,     0.,     0.,     0.],\n       [  841., 11879., 12249., ...,     0.,     0.,     0.]])"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reset_text(text, seq_len):\n",
    "    dataset = np.zeros((len(text),seq_len))\n",
    "    for index,sentence in enumerate(text):\n",
    "        if len(sentence) < seq_len:\n",
    "            dataset[index, :len(sentence)] = sentence  # 后面填充0\n",
    "        else:\n",
    "            dataset[index, :] = sentence[:seq_len]  # 截断\n",
    "    return dataset\n",
    "\n",
    "dataset = reset_text(text2ints, seq_len=22)\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "## 转化为张量\n",
    "dataset_tensor = torch.from_numpy(dataset)\n",
    "label_tensor = torch.from_numpy(new_labels)\n",
    "print(type(dataset_tensor), type(label_tensor))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集:torch.Size([12792, 22])----torch.Size([12792])\n",
      "验证集:torch.Size([3198, 22])----torch.Size([3198])\n"
     ]
    }
   ],
   "source": [
    "all_samples = len(dataset_tensor)\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.2\n",
    "train = dataset_tensor[:int(train_ratio*all_samples)]\n",
    "train_labels = label_tensor[:int(train_ratio*all_samples)]\n",
    "\n",
    "val = dataset_tensor[int(train_ratio*all_samples):]\n",
    "val_labels = label_tensor[int(train_ratio*all_samples):]\n",
    "\n",
    "print(\"训练集:{}----{}\".format(train.shape, train_labels.shape))\n",
    "\n",
    "print(\"验证集:{}----{}\".format(val.shape,val_labels.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(train, train_labels)\n",
    "val_dataset = TensorDataset(val, val_labels)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "num_worker应该不大于2 https://www.cnblogs.com/longyi8013/p/14880432.html"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "class SentimentNet(nn.Module):\n",
    "    def __init__(self, input_size, embedding_dim, hidden_dim, output_size, num_layers, dropout=0.5):\n",
    "        super(SentimentNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding= nn.Embedding(input_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, dropout=dropout,batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(128, output_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "             x:  (128,10)\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "        x = x.long()\n",
    "        embeds = self.embedding(x) # embeds(128,10,200)\n",
    "\n",
    "\n",
    "        #  out(128,22,128)--batch_size,seq_len, hidden_size\n",
    "        #  hidden是个元组{h_n,c_n}每个都是(2, 128,128) -- num_layer,batch_size, hidden_size\n",
    "        out,hidden = self.lstm(embeds, hidden)\n",
    "        out = self.linear(out[:, -1, :]) # out(128，128)\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out) # out(128, 6)\n",
    "\n",
    "        return out, hidden # hidden (h_n, c_n)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters())\n",
    "        # h_0, c_0\n",
    "        return (weight.new_zeros(self.num_layers, batch_size, self.hidden_dim),\n",
    "                weight.new_zeros(self.num_layers, batch_size, self.hidden_dim))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "input_size = len(word2int)\n",
    "output_size = len(category)\n",
    "embedding_dim = 200\n",
    "hidden_dim= 128\n",
    "num_layers= 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "SentimentNet(\n  (embedding): Embedding(13478, 200)\n  (lstm): LSTM(200, 128, num_layers=2, batch_first=True, dropout=0.5)\n  (linear): Linear(in_features=128, out_features=128, bias=True)\n  (relu): ReLU()\n  (linear2): Linear(in_features=128, out_features=6, bias=True)\n  (dropout): Dropout(p=0.4, inplace=False)\n)"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentimentNet(input_size, embedding_dim, hidden_dim, output_size, num_layers)\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-3)\n",
    "# Decay LR by a factor of 0.1 every 3 epochs\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "def train(model, data_loader, criterion, optimizer, scheduler, num_epochs):\n",
    "    train_process = dict()\n",
    "    train_loss_epoch10, val_loss_epoch10= [],[]\n",
    "    val_acc_epoch10 = []\n",
    "    for epoch in range(num_epochs):\n",
    "        hs = model.init_hidden(batch_size)\n",
    "        train_loss = []\n",
    "        train_correct = 0\n",
    "        model.train()\n",
    "        for data, target in data_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output,hs = model(data, hs)\n",
    "            preds = torch.argmax(output, dim=1)\n",
    "            train_correct += torch.sum(preds==target)\n",
    "\n",
    "            hs = tuple([h.data for h in hs])\n",
    "            loss = criterion(output, target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "        print(f\"Epoch [{epoch}/{num_epochs-1}]---train loss {np.mean(train_loss):>.5f}\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            validation_loss, validation_acc = validation(model, val_loader, criterion)\n",
    "\n",
    "            train_loss_epoch10.append(np.mean(train_loss))\n",
    "            val_loss_epoch10.append(validation_loss)\n",
    "            val_acc_epoch10.append(validation_acc)\n",
    "\n",
    "    train_process[\"train_loss\"] = train_loss_epoch10\n",
    "    train_process[\"val_loss\"] = val_loss_epoch10\n",
    "    train_process[\"val_acc\"] = val_acc_epoch10\n",
    "    return train_process\n",
    "\n",
    "def validation(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    hs = model.init_hidden(batch_size)\n",
    "    val_loss = []\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            outs,hs = model(data,hs)\n",
    "            hs = tuple([h.data for h in hs])\n",
    "\n",
    "            loss = criterion(outs, target)\n",
    "            preds = torch.argmax(outs, dim=1)\n",
    "            val_loss.append(loss.item())\n",
    "            val_correct += torch.sum(preds==target)\n",
    "    print(f\"--------------------------------validation loss is: {np.mean(val_loss):>.5f}, acc is: {100*val_correct/len(val_loader.dataset):>.2f}%\")\n",
    "    return np.mean(val_loss), val_correct/len(val_loader.dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/99]---train loss 1.59561\n",
      "--------------------------------validation loss is: 1.57851, acc is: 31.36%\n",
      "Epoch [1/99]---train loss 1.58089\n",
      "Epoch [2/99]---train loss 1.45152\n",
      "Epoch [3/99]---train loss 1.16529\n",
      "Epoch [4/99]---train loss 1.04221\n",
      "Epoch [5/99]---train loss 0.92176\n",
      "Epoch [6/99]---train loss 0.79348\n",
      "Epoch [7/99]---train loss 0.66122\n",
      "Epoch [8/99]---train loss 0.55338\n",
      "Epoch [9/99]---train loss 0.35823\n",
      "Epoch [10/99]---train loss 0.19518\n",
      "--------------------------------validation loss is: 0.59617, acc is: 80.68%\n",
      "Epoch [11/99]---train loss 0.16765\n",
      "Epoch [12/99]---train loss 0.15159\n",
      "Epoch [13/99]---train loss 0.13251\n",
      "Epoch [14/99]---train loss 0.12101\n",
      "Epoch [15/99]---train loss 0.11351\n",
      "Epoch [16/99]---train loss 0.10680\n",
      "Epoch [17/99]---train loss 0.09633\n",
      "Epoch [18/99]---train loss 0.08807\n",
      "Epoch [19/99]---train loss 0.08218\n",
      "Epoch [20/99]---train loss 0.07582\n",
      "--------------------------------validation loss is: 0.68111, acc is: 81.52%\n",
      "Epoch [21/99]---train loss 0.07480\n",
      "Epoch [22/99]---train loss 0.07791\n",
      "Epoch [23/99]---train loss 0.07715\n",
      "Epoch [24/99]---train loss 0.07707\n",
      "Epoch [25/99]---train loss 0.07797\n",
      "Epoch [26/99]---train loss 0.07871\n",
      "Epoch [27/99]---train loss 0.07272\n",
      "Epoch [28/99]---train loss 0.06863\n",
      "Epoch [29/99]---train loss 0.07654\n",
      "Epoch [30/99]---train loss 0.07362\n",
      "--------------------------------validation loss is: 0.70063, acc is: 81.68%\n",
      "Epoch [31/99]---train loss 0.06811\n",
      "Epoch [32/99]---train loss 0.07395\n",
      "Epoch [33/99]---train loss 0.07473\n",
      "Epoch [34/99]---train loss 0.07043\n",
      "Epoch [35/99]---train loss 0.06870\n",
      "Epoch [36/99]---train loss 0.06830\n",
      "Epoch [37/99]---train loss 0.06784\n",
      "Epoch [38/99]---train loss 0.06939\n",
      "Epoch [39/99]---train loss 0.06911\n",
      "Epoch [40/99]---train loss 0.06961\n",
      "--------------------------------validation loss is: 0.68960, acc is: 81.61%\n",
      "Epoch [41/99]---train loss 0.07013\n",
      "Epoch [42/99]---train loss 0.06972\n",
      "Epoch [43/99]---train loss 0.07017\n",
      "Epoch [44/99]---train loss 0.06829\n",
      "Epoch [45/99]---train loss 0.07317\n",
      "Epoch [46/99]---train loss 0.07148\n",
      "Epoch [47/99]---train loss 0.07073\n",
      "Epoch [48/99]---train loss 0.07284\n",
      "Epoch [49/99]---train loss 0.07080\n",
      "Epoch [50/99]---train loss 0.06937\n",
      "--------------------------------validation loss is: 0.70722, acc is: 81.89%\n",
      "Epoch [51/99]---train loss 0.06767\n",
      "Epoch [52/99]---train loss 0.06935\n",
      "Epoch [53/99]---train loss 0.06797\n",
      "Epoch [54/99]---train loss 0.06794\n",
      "Epoch [55/99]---train loss 0.07033\n",
      "Epoch [56/99]---train loss 0.07062\n",
      "Epoch [57/99]---train loss 0.06867\n",
      "Epoch [58/99]---train loss 0.06731\n",
      "Epoch [59/99]---train loss 0.07565\n",
      "Epoch [60/99]---train loss 0.06430\n",
      "--------------------------------validation loss is: 0.69929, acc is: 82.11%\n",
      "Epoch [61/99]---train loss 0.06741\n",
      "Epoch [62/99]---train loss 0.07396\n",
      "Epoch [63/99]---train loss 0.07259\n",
      "Epoch [64/99]---train loss 0.06987\n",
      "Epoch [65/99]---train loss 0.06575\n",
      "Epoch [66/99]---train loss 0.07256\n",
      "Epoch [67/99]---train loss 0.07187\n",
      "Epoch [68/99]---train loss 0.06791\n",
      "Epoch [69/99]---train loss 0.06912\n",
      "Epoch [70/99]---train loss 0.07180\n",
      "--------------------------------validation loss is: 0.69846, acc is: 81.86%\n",
      "Epoch [71/99]---train loss 0.07166\n",
      "Epoch [72/99]---train loss 0.06747\n",
      "Epoch [73/99]---train loss 0.07121\n",
      "Epoch [74/99]---train loss 0.07022\n",
      "Epoch [75/99]---train loss 0.07101\n",
      "Epoch [76/99]---train loss 0.07298\n",
      "Epoch [77/99]---train loss 0.06871\n",
      "Epoch [78/99]---train loss 0.07246\n",
      "Epoch [79/99]---train loss 0.06828\n",
      "Epoch [80/99]---train loss 0.06782\n",
      "--------------------------------validation loss is: 0.69289, acc is: 82.05%\n",
      "Epoch [81/99]---train loss 0.06824\n",
      "Epoch [82/99]---train loss 0.07276\n",
      "Epoch [83/99]---train loss 0.07032\n",
      "Epoch [84/99]---train loss 0.07270\n",
      "Epoch [85/99]---train loss 0.06942\n",
      "Epoch [86/99]---train loss 0.07176\n",
      "Epoch [87/99]---train loss 0.07049\n",
      "Epoch [88/99]---train loss 0.07224\n",
      "Epoch [89/99]---train loss 0.07043\n",
      "Epoch [90/99]---train loss 0.06835\n",
      "--------------------------------validation loss is: 0.70442, acc is: 81.77%\n",
      "Epoch [91/99]---train loss 0.07120\n",
      "Epoch [92/99]---train loss 0.06803\n",
      "Epoch [93/99]---train loss 0.07250\n",
      "Epoch [94/99]---train loss 0.07153\n",
      "Epoch [95/99]---train loss 0.07114\n",
      "Epoch [96/99]---train loss 0.07422\n",
      "Epoch [97/99]---train loss 0.06800\n",
      "Epoch [98/99]---train loss 0.07279\n",
      "Epoch [99/99]---train loss 0.07051\n"
     ]
    }
   ],
   "source": [
    "train_process = train(model, train_loader, criterion, optimizer,exp_lr_scheduler, num_epochs=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [116]\u001B[0m, in \u001B[0;36m<cell line: 14>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     12\u001B[0m plt\u001B[38;5;241m.\u001B[39mylabel(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     13\u001B[0m plt\u001B[38;5;241m.\u001B[39mtitle(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mValidation Accuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 14\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_process\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mval_acc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\pyplot.py:2757\u001B[0m, in \u001B[0;36mplot\u001B[1;34m(scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2755\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes\u001B[38;5;241m.\u001B[39mplot)\n\u001B[0;32m   2756\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mplot\u001B[39m(\u001B[38;5;241m*\u001B[39margs, scalex\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, scaley\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m-> 2757\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m gca()\u001B[38;5;241m.\u001B[39mplot(\n\u001B[0;32m   2758\u001B[0m         \u001B[38;5;241m*\u001B[39margs, scalex\u001B[38;5;241m=\u001B[39mscalex, scaley\u001B[38;5;241m=\u001B[39mscaley,\n\u001B[0;32m   2759\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m: data} \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m {}), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\axes\\_axes.py:1632\u001B[0m, in \u001B[0;36mAxes.plot\u001B[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1390\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1391\u001B[0m \u001B[38;5;124;03mPlot y versus x as lines and/or markers.\u001B[39;00m\n\u001B[0;32m   1392\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1629\u001B[0m \u001B[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001B[39;00m\n\u001B[0;32m   1630\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1631\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m cbook\u001B[38;5;241m.\u001B[39mnormalize_kwargs(kwargs, mlines\u001B[38;5;241m.\u001B[39mLine2D)\n\u001B[1;32m-> 1632\u001B[0m lines \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_lines(\u001B[38;5;241m*\u001B[39margs, data\u001B[38;5;241m=\u001B[39mdata, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)]\n\u001B[0;32m   1633\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m lines:\n\u001B[0;32m   1634\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_line(line)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\axes\\_base.py:312\u001B[0m, in \u001B[0;36m_process_plot_var_args.__call__\u001B[1;34m(self, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m    310\u001B[0m     this \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m args[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m    311\u001B[0m     args \u001B[38;5;241m=\u001B[39m args[\u001B[38;5;241m1\u001B[39m:]\n\u001B[1;32m--> 312\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_plot_args\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\axes\\_base.py:490\u001B[0m, in \u001B[0;36m_process_plot_var_args._plot_args\u001B[1;34m(self, tup, kwargs, return_kwargs)\u001B[0m\n\u001B[0;32m    488\u001B[0m     y \u001B[38;5;241m=\u001B[39m _check_1d(xy[\u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m    489\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 490\u001B[0m     x, y \u001B[38;5;241m=\u001B[39m \u001B[43mindex_of\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxy\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    492\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxes\u001B[38;5;241m.\u001B[39mxaxis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    493\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxes\u001B[38;5;241m.\u001B[39mxaxis\u001B[38;5;241m.\u001B[39mupdate_units(x)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\cbook\\__init__.py:1652\u001B[0m, in \u001B[0;36mindex_of\u001B[1;34m(y)\u001B[0m\n\u001B[0;32m   1650\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m   1651\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1652\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43m_check_1d\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1653\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (np\u001B[38;5;241m.\u001B[39mVisibleDeprecationWarning, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[0;32m   1654\u001B[0m     \u001B[38;5;66;03m# NumPy 1.19 will warn on ragged input, and we can't actually use it.\u001B[39;00m\n\u001B[0;32m   1655\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\cbook\\__init__.py:1304\u001B[0m, in \u001B[0;36m_check_1d\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m   1302\u001B[0m \u001B[38;5;124;03m\"\"\"Convert scalars to 1D arrays; pass-through arrays as is.\"\"\"\u001B[39;00m\n\u001B[0;32m   1303\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(x, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mshape\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(x\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m-> 1304\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43matleast_1d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1305\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1306\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1307\u001B[0m         \u001B[38;5;66;03m# work around\u001B[39;00m\n\u001B[0;32m   1308\u001B[0m         \u001B[38;5;66;03m# https://github.com/pandas-dev/pandas/issues/27775 which\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1319\u001B[0m         \u001B[38;5;66;03m# This code should correctly identify and coerce to a\u001B[39;00m\n\u001B[0;32m   1320\u001B[0m         \u001B[38;5;66;03m# numpy array all pandas versions.\u001B[39;00m\n",
      "File \u001B[1;32m<__array_function__ internals>:5\u001B[0m, in \u001B[0;36matleast_1d\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[1;32mD:\\Develop\\Anaconda3\\envs\\jupyter\\lib\\site-packages\\numpy\\core\\shape_base.py:65\u001B[0m, in \u001B[0;36matleast_1d\u001B[1;34m(*arys)\u001B[0m\n\u001B[0;32m     63\u001B[0m res \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ary \u001B[38;5;129;01min\u001B[39;00m arys:\n\u001B[1;32m---> 65\u001B[0m     ary \u001B[38;5;241m=\u001B[39m \u001B[43masanyarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mary\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     66\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ary\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     67\u001B[0m         result \u001B[38;5;241m=\u001B[39m ary\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32mD:\\Develop\\Anaconda3\\envs\\jupyter\\lib\\site-packages\\torch\\_tensor.py:757\u001B[0m, in \u001B[0;36mTensor.__array__\u001B[1;34m(self, dtype)\u001B[0m\n\u001B[0;32m    755\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(Tensor\u001B[38;5;241m.\u001B[39m__array__, (\u001B[38;5;28mself\u001B[39m,), \u001B[38;5;28mself\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[0;32m    756\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 757\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    758\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    759\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnumpy()\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mTypeError\u001B[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1152x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(train_process[\"train_loss\"],label=\"train-loss\")\n",
    "plt.plot(train_process[\"val_loss\"],label=\"val-loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.legend(labels=[\"\"])\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Validation Accuracy\")\n",
    "plt.plot(train_process[\"val_acc\"].cpu())\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i like to have the same breathless feeling as a reader eager to see what will happen next\n",
      "   预测结果是:  joy\n",
      "i don t feel particularly agitated\n",
      "   预测结果是:  fear\n",
      "i feel like i m defective or something for not having baby fever\n",
      "   预测结果是:  sadness\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "texts = [\"i like to have the same breathless feeling as a reader eager to see what will happen next\",\n",
    "        \"i don t feel particularly agitated\",\n",
    "         \"i feel like i m defective or something for not having baby fever\"\n",
    "       ]\n",
    "def converts(text):\n",
    "    text = remove_hyperlinks(text)\n",
    "    text = remove_currencies(text)\n",
    "    text = remove_number(text)\n",
    "    new_text = remove_punctuation(text)\n",
    "    test_text_ints = [word2int[word.lower()]for word in new_text.split() if word in word2int.keys()]\n",
    "    return test_text_ints\n",
    "\n",
    "def predict(model):\n",
    "    test_text_ints = [converts(text) for text in texts]\n",
    "\n",
    "    new_test_text_ints = reset_text(test_text_ints, seq_len=22)\n",
    "    text_tensor = torch.from_numpy(new_test_text_ints)\n",
    "\n",
    "    batch_size = text_tensor.size(0)\n",
    "    hs = model.init_hidden(batch_size)\n",
    "\n",
    "    text_tensor = text_tensor.to(device)\n",
    "    outs, hs = model(text_tensor,hs)\n",
    "    preds = torch.argmax(outs, dim=1)\n",
    "\n",
    "    for i in range(len(texts)):\n",
    "        print(texts[i])\n",
    "        print(\"   预测结果是: \", category[int(preds[i])])\n",
    "\n",
    "predict(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}